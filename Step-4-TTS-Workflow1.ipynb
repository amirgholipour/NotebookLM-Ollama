{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a1b5d7-fd98-4fa2-9bea-e68c514b9245",
   "metadata": {},
   "source": [
    "## Notebook 4: TTS Workflow\n",
    "\n",
    "We have the exact podcast transcripts ready now to generate our audio for the Podcast.\n",
    "\n",
    "In this notebook, we will learn how to generate Audio using  `Kokoro` model first. \n",
    "\n",
    "After that, we will use the output from Notebook 3 to generate our complete podcast\n",
    "\n",
    "Note: Please feel free to extend this notebook with newer models. The above two were chosen after some tests using a sample prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a0ac082-cc75-433e-8042-d1989b26c58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                         ID              SIZE      MODIFIED     \n",
      "hf.co/OuteAI/OuteTTS-0.3-500M-GGUF:Q4_K_S                    76c6be93d29c    391 MB    2 days ago      \n",
      "hf.co/OuteAI/OuteTTS-0.2-500M-GGUF:Q8_0                      0a6c38a67073    536 MB    3 days ago      \n",
      "mistral-small:24b                                            8039dd90c113    14 GB     7 days ago      \n",
      "llama3.2-vision:11b                                          085a1fdae525    7.9 GB    7 days ago      \n",
      "mistral-nemo:latest                                          994f3b8b7801    7.1 GB    7 days ago      \n",
      "granite3.2:8b                                                9bcb3335083f    4.9 GB    8 days ago      \n",
      "phi4-mini:latest                                             60f202f815d7    2.8 GB    8 days ago      \n",
      "granite3.2-vision:latest                                     3be41a661804    2.4 GB    9 days ago      \n",
      "phi4:latest                                                  ac896e5b8b34    9.1 GB    2 weeks ago     \n",
      "nomic-embed-text:latest                                      0a109f422b47    274 MB    2 weeks ago     \n",
      "llama3.2:3b                                                  a80c4f17acd5    2.0 GB    4 weeks ago     \n",
      "deepseek-r1:8b                                               28f8fd6cdc67    4.9 GB    4 weeks ago     \n",
      "hf.co/lmstudio-community/Qwen2.5-7B-Instruct-1M-GGUF:Q8_0    2d4b678222de    8.1 GB    5 weeks ago     \n",
      "deepseek-r1:32b                                              38056bbcbb2d    19 GB     5 weeks ago     \n",
      "qwen2.5-coder:32b                                            4bd6cbf2d094    19 GB     3 months ago    \n",
      "mxbai-embed-large:latest                                     468836162de7    669 MB    3 months ago    \n",
      "llama3.2:1b                                                  baf6a787fdff    1.3 GB    4 months ago    \n"
     ]
    }
   ],
   "source": [
    "!ollama list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd866ac-8ea6-486d-96cd-7594a8c329e0",
   "metadata": {},
   "source": [
    "Credit: [This](https://colab.research.google.com/drive/1dWWkZzvu7L9Bunq9zvD-W02RFUXoW-Pd?usp=sharing#scrollTo=68QtoUqPWdLk) Colab was used for starter code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2c0ee-7527-46e4-9c07-e6dac34376e5",
   "metadata": {},
   "source": [
    "We can install these packages for speedups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a8a71-7e78-42fa-8c5a-b49c6f82f0ab",
   "metadata": {},
   "source": [
    "!for KoKoro, you need to follow this if the base\n",
    "\n",
    "* 1ï¸âƒ£ Install kokoro\n",
    "!pip install -q kokoro>=0.8.2 soundfile\n",
    "* 2ï¸âƒ£ Install espeak, used for English OOD fallback and some non-English languages\n",
    "!apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
    "or\n",
    "brew install espeak-ng   # in MacOS\n",
    "\n",
    "if you face any issue regarding to thinc as a dependency for packages like spaCy\n",
    "    * Install Python 3.12.6.â€‹\n",
    "    * Create and activate a virtual environment.â€‹\n",
    "    * Install thinc or spaCy within this environment.â€‹\n",
    "\n",
    "Install with Build Isolation Disabled: If you prefer to use Python 3.13, you can try installing thinc with build isolation disabled:\n",
    "\n",
    "    Ensure numpy is installed:â€‹\n",
    "\n",
    "pip install numpy\n",
    "\n",
    "Install thinc without build isolation:â€‹\n",
    "\n",
    "    'pip install --no-build-isolation thinc'\n",
    "\n",
    "Use Conda for Installation: Conda can handle dependencies more effectively on macOS:\n",
    "\n",
    "    'Create and activate a conda environment:â€‹'\n",
    "\n",
    "conda create -n myenv python=3.12\n",
    "conda activate myenv\n",
    "\n",
    "Install thinc using conda:â€‹\n",
    "\n",
    "        'conda install -c conda-forge thinc'\n",
    "\n",
    "For more detailed information on installing thinc, refer to the official installation guide. â€‹\n",
    "thinc.ai\n",
    "\n",
    "If you continue to experience issues, consider consulting the spaCy GitHub discussions or Stack Overflow for community support. â€‹\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07672295-af30-4b4b-b11c-44ca938436cd",
   "metadata": {},
   "source": [
    "Let's import the necessary frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89d75859-e0f9-40e3-931d-64aa3d273f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f442758d-c48f-48ac-a4b0-558695290aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BarkModel, AutoProcessor, AutoTokenizer\n",
    "import torch\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ba1903-59c8-4004-bb39-1761cd3d140e",
   "metadata": {},
   "source": [
    "### Testing the Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2523c565-bb35-4fae-bdcb-cba11ef0b572",
   "metadata": {},
   "source": [
    "Let's try generating audio using Kokoro model to understand how they work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b62df5-5ea3-4913-832a-da59f7cf8de2",
   "metadata": {},
   "source": [
    "Please set `device = \"cuda\"` below if you're using a single GPU node."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309d0678-880b-44cb-a54a-9408b3c8d644",
   "metadata": {},
   "source": [
    "#### Kokoro Model\n",
    "\n",
    "Let's try using the Parler Model first and generate a short segment with speaker Laura's voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bebbf1-48ff-44d1-a7bc-8daaa090da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ Install kokoro\n",
    "# !pip install -q kokoro>=0.8.2 soundfile\n",
    "# 2ï¸âƒ£ Install espeak, used for English OOD fallback and some non-English languages\n",
    "# !apt-get -qq -y install espeak-ng > /dev/null 2>&1\n",
    "# ðŸ‡ªðŸ‡¸ 'e' => Spanish es\n",
    "# ðŸ‡«ðŸ‡· 'f' => French fr-fr\n",
    "# ðŸ‡®ðŸ‡³ 'h' => Hindi hi\n",
    "# ðŸ‡®ðŸ‡¹ 'i' => Italian it\n",
    "# ðŸ‡§ðŸ‡· 'p' => Brazilian Portuguese pt-br\n",
    "\n",
    "# 3ï¸âƒ£ Initalize a pipeline\n",
    "from kokoro import KPipeline\n",
    "from IPython.display import display, Audio\n",
    "import soundfile as sf\n",
    "# ðŸ‡ºðŸ‡¸ 'a' => American English, ðŸ‡¬ðŸ‡§ 'b' => British English\n",
    "# ðŸ‡¯ðŸ‡µ 'j' => Japanese: pip install misaki[ja]\n",
    "# ðŸ‡¨ðŸ‡³ 'z' => Mandarin Chinese: pip install misaki[zh]\n",
    "pipeline = KPipeline(lang_code='a') # <= make sure lang_code matches voice\n",
    "\n",
    "# This text is for demonstration purposes only, unseen during training\n",
    "text = '''\n",
    "The sky above the port was the color of television, tuned to a dead channel.\n",
    "\"It's not like I'm using,\" Case heard someone say, as he shouldered his way through the crowd around the door of the Chat. \"It's like my body's developed this massive drug deficiency.\"\n",
    "It was a Sprawl voice and a Sprawl joke. The Chatsubo was a bar for professional expatriates; you could drink there for a week and never hear two words in Japanese.\n",
    "\n",
    "These were to have an enormous impact, not only because they were associated with Constantine, but also because, as in so many other areas, the decisions taken by Constantine (or in his name) were to have great significance for centuries to come. One of the main issues was the shape that Christian churches were to take, since there was not, apparently, a tradition of monumental church buildings when Constantine decided to help the Christian church build a series of truly spectacular structures. The main form that these churches took was that of the basilica, a multipurpose rectangular structure, based ultimately on the earlier Greek stoa, which could be found in most of the great cities of the empire. Christianity, unlike classical polytheism, needed a large interior space for the celebration of its religious services, and the basilica aptly filled that need. We naturally do not know the degree to which the emperor was involved in the design of new churches, but it is tempting to connect this with the secular basilica that Constantine completed in the Roman forum (the so-called Basilica of Maxentius) and the one he probably built in Trier, in connection with his residence in the city at a time when he was still caesar.\n",
    "\n",
    "[Kokoro](/kËˆOkÉ™É¹O/) is an open-weight TTS model with 82 million parameters. Despite its lightweight architecture, it delivers comparable quality to larger models while being significantly faster and more cost-efficient. With Apache-licensed weights, [Kokoro](/kËˆOkÉ™É¹O/) can be deployed anywhere from production environments to personal projects.\n",
    "'''\n",
    "# text = 'ã€Œã‚‚ã—ãŠã‚ŒãŒãŸã å¶ç„¶ã€ãã—ã¦ã“ã†ã—ã‚ˆã†ã¨ã„ã†ã¤ã‚‚ã‚Šã§ãªãã“ã“ã«ç«‹ã£ã¦ã„ã‚‹ã®ãªã‚‰ã€ã¡ã‚‡ã£ã¨ã°ã‹ã‚Šçµ¶æœ›ã™ã‚‹ã¨ã“ã‚ã ãªã€ã¨ã€ãã‚“ãªã“ã¨ãŒå½¼ã®é ­ã«æ€ã„æµ®ã‹ã‚“ã ã€‚'\n",
    "# text = 'ä¸­åœ‹äººæ°‘ä¸ä¿¡é‚ªä¹Ÿä¸æ€•é‚ªï¼Œä¸æƒ¹äº‹ä¹Ÿä¸æ€•äº‹ï¼Œä»»ä½•å¤–åœ‹ä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒæ‹¿è‡ªå·±çš„æ ¸å¿ƒåˆ©ç›Šåšäº¤æ˜“ï¼Œä¸è¦æŒ‡æœ›æˆ‘å€‘æœƒåžä¸‹æå®³æˆ‘åœ‹ä¸»æ¬Šã€å®‰å…¨ã€ç™¼å±•åˆ©ç›Šçš„è‹¦æžœï¼'\n",
    "# text = 'Los partidos polÃ­ticos tradicionales compiten con los populismos y los movimientos asamblearios.'\n",
    "# text = 'Le dromadaire resplendissant dÃ©ambulait tranquillement dans les mÃ©andres en mastiquant de petites feuilles vernissÃ©es.'\n",
    "# text = 'à¤Ÿà¥à¤°à¤¾à¤‚à¤¸à¤ªà¥‹à¤°à¥à¤Ÿà¤°à¥‹à¤‚ à¤•à¥€ à¤¹à¤¡à¤¼à¤¤à¤¾à¤² à¤²à¤—à¤¾à¤¤à¤¾à¤° à¤ªà¤¾à¤‚à¤šà¤µà¥‡à¤‚ à¤¦à¤¿à¤¨ à¤œà¤¾à¤°à¥€, à¤¦à¤¿à¤¸à¤‚à¤¬à¤° à¤¸à¥‡ à¤‡à¤²à¥‡à¤•à¥à¤Ÿà¥à¤°à¥‰à¤¨à¤¿à¤• à¤Ÿà¥‹à¤² à¤•à¤²à¥‡à¤•à¥à¤¶à¤¨à¤² à¤¸à¤¿à¤¸à¥à¤Ÿà¤®'\n",
    "# text = \"Allora cominciava l'insonnia, o un dormiveglia peggiore dell'insonnia, che talvolta assumeva i caratteri dell'incubo.\"\n",
    "# text = 'Elabora relatÃ³rios de acompanhamento cronolÃ³gico para as diferentes unidades do Departamento que propÃµem contratos.'\n",
    "\n",
    "# 4ï¸âƒ£ Generate, display, and save audio files in a loop.\n",
    "generator = pipeline(\n",
    "    text, voice='af_heart', # <= change voice here\n",
    "    speed=1, split_pattern=r'\\n+'\n",
    ")\n",
    "for i, (gs, ps, audio) in enumerate(generator):\n",
    "    print(i)  # i => index\n",
    "    print(gs) # gs => graphemes/text\n",
    "    print(ps) # ps => phonemes\n",
    "    display(Audio(data=audio, rate=24000, autoplay=i==0))\n",
    "    sf.write(f'{i}.wav', audio, 24000) # save each audio file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd650176-ab17-47a7-8e02-10dc9ca9e852",
   "metadata": {},
   "source": [
    "## Bringing it together: Making the Podcast\n",
    "\n",
    "Okay now that we understand everything-we can now use the complete pipeline to generate the entire podcast\n",
    "\n",
    "Let's load in our pickle file from earlier and proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b1dca30f-1226-4002-8e02-fd97e78ecc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./resources/podcast_ready_data.pkl', 'rb') as file:\n",
    "    PODCAST_TEXT = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96843175",
   "metadata": {},
   "source": [
    "Let's define load in the TTS model and set it's hyper-parameters for discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f6fa24-fe07-4702-850f-0428bfadd2dc",
   "metadata": {},
   "source": [
    "We will concatenate the generated segments of audio and also their respective sampling rates since we will require this to generate the final audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9b333e36-9579-4237-b329-e2911229be42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b2490c-012f-4e35-8890-cd6a5eaf4cc4",
   "metadata": {},
   "source": [
    "Function generate text for speaker 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "14de7ad3-128b-49b7-93be-63d83684a34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Function to determine speed range based on text length relative to average length\n",
    "def determine_speed_range(text_length, average_length):\n",
    "    if text_length < average_length:\n",
    "        return 0.8, .97  # Shorter than average: lower speed range\n",
    "    else:\n",
    "        return .97, 1.15  # Average or longer: higher speed range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "92b84384-8694-4ca8-9b8b-d5a0dbc4242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speaker1_audio(text,average_length):\n",
    "    \"\"\"Generate audio using ParlerTTS for Speaker 1\"\"\"\n",
    "    text_length = len(text)\n",
    "    # speed = random.uniform(.75, 1.2)\n",
    "    min_speed, max_speed = determine_speed_range(text_length, average_length)\n",
    "    speed = random.uniform(min_speed, max_speed)\n",
    "    print(speed)\n",
    "    generator = pipeline(\n",
    "        text, voice='am_liam', # <= change voice here  af_heart am_eric\n",
    "        speed=speed, split_pattern=r'\\n+'\n",
    "    )\n",
    "    for i, (gs, ps, audio) in enumerate(generator): \n",
    "        # Assuming 'audio' is your tensor\n",
    "        audio_tensor = audio.cpu().detach().numpy()\n",
    "        audio_array = np.squeeze(audio_tensor)\n",
    "\n",
    "    return audio_array,24000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5dac8-30a6-4aa2-a983-b5f1df3d56af",
   "metadata": {},
   "source": [
    "Function to generate text for speaker 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c828b750-2413-4d1f-90e3-9cd9efdfbf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speaker2_audio(text,average_length):\n",
    "    \"\"\"Generate audio using ParlerTTS for Speaker 1\"\"\"\n",
    "    text_length = len(text)\n",
    "    # speed = random.uniform(.75, 1.2)\n",
    "    min_speed, max_speed = determine_speed_range(text_length, average_length)\n",
    "    speed = random.uniform(min_speed, max_speed)\n",
    "    print(speed)\n",
    "    generator = pipeline(\n",
    "        text, voice='af_heart', # <= change voice here  af_heart af_jessica\n",
    "        speed=speed, split_pattern=r'\\n+'\n",
    "    )\n",
    "    for i, (gs, ps, audio) in enumerate(generator):\n",
    "        # Assuming 'audio' is your tensor\n",
    "        audio_tensor = audio.cpu().detach().numpy()\n",
    "        audio_array = np.squeeze(audio_tensor)\n",
    "\n",
    "    return audio_array,24000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea67fd1-9405-4fce-b08b-df5e11d0bf37",
   "metadata": {},
   "source": [
    "Helper function to convert the numpy output from the models into audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2cd50533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import ast\n",
    "\n",
    "def numpy_to_audio_segment(audio_arr, sampling_rate):\n",
    "    \"\"\"Convert NumPy array to AudioSegment.\"\"\"\n",
    "    # Ensure the NumPy array is in the correct format\n",
    "    if audio_arr.dtype != np.int16:\n",
    "        # Scale and convert the float array to int16\n",
    "        audio_arr = (audio_arr * 32767).astype(np.int16)\n",
    "    \n",
    "    # Create an AudioSegment instance from the raw data\n",
    "    audio_segment = AudioSegment(\n",
    "        audio_arr.tobytes(), \n",
    "        frame_rate=sampling_rate,\n",
    "        sample_width=audio_arr.dtype.itemsize, \n",
    "        channels=1\n",
    "    )\n",
    "    \n",
    "    return audio_segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "278a756e-c8e5-473f-93a6-e97871e301ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 1: Welcome back to another episode where we delve into the captivating realm of artificial intelligence â€” Knowledge Distillation. Imagine teaching your brainy buddy everything they know, but this time, it's all about bots and coding instead of conversations and hugs! I'm thrilled to be joined by a fellow AI enthusiast who's eager to learn more about this thrilling topic.\n",
      "Speaker 2: [Excited] Hi there! So, what exactly is Knowledge Distillation? Sounds like some sort of robot secret society!\n",
      "Speaker 1: Welcome aboard, buddy! It's actually the process of taking advanced capabilities from premium Large Language Models (LLMs) â€” think top-of-the-line AI brains that cost an arm and a leg â€” and condensing their knowledge into more accessible open-source models.\n",
      "Speaker 2: Oh wow, so these LLMs are like genius AI beings? But they're pricey and exclusive?\n",
      "Speaker 1: Precisely! Models like GPT-4 or Gemini are loaded with incredible problem-solving skills, but they come at a high cost. That's where Knowledge Distillation steps in â€” it transfers that top-tier knowledge into more accessible open-source LLMs like LLaMA and Mistral.\n",
      "Speaker 2: Amazing! So the end goal is to bring smart AI tech to the masses, not just those with deep wallets?\n",
      "Speaker 1: Exactly! It's about making advanced capabilities more widespread. Plus, these open-source models can also become more efficient and powerful through distillation.\n",
      "Speaker 2: Umm, but how does this work exactly? How do they transfer the knowledge?\n",
      "Speaker 1: Let me break it down for you! Knowledge Distillation involves various mechanisms like supervised fine-tuning. We train a model on a smaller dataset to adapt it to specific tasks or domains.\n",
      "Speaker 2: How does that work in practice?\n",
      "Speaker 1: Think of it this way: imagine GPT-4, the teacher who knows everything. Now, our student model, LLaMA, learns from this 'teacher' without needing access to all their proprietary data or resources. We teach LLaMA using techniques like soft target training where it learns from the softened softmax output of GPT-4.\n",
      "Speaker 2: Ohhh, so kinda like a mentorship program?\n",
      "Speaker 1: Exactly! But there's more. Data Augmentation (DA) is another crucial aspect. This isn't just about expanding the dataset; it's about generating novel, context-rich training data tailored to specific domains and skills using LLMs.\n",
      "Speaker 2: Wow, that sounds super advanced!\n",
      "Speaker 1: Yeah, it really is! By creating targeted datasets, we ensure the distilled model gains a deep understanding of its domain. The goal isn't just making more data; it's about ensuring that new data is rich and relevant.\n",
      "Speaker 2: Right, so itâ€™s like giving LLaMA not only GPT-4's knowledge but also teaching it to think like GPT-4?\n",
      "Speaker 1: Precisely! The distillation process includes strategies like chain-of-thought prompting. This helps the student model learn the reasoning process of its 'teacher', enhancing problem-solving and decision-making capabilities.\n",
      "Speaker 2: That's mind-blowing! So itâ€™s not just about transferring data, but also transferring thought processes?\n",
      "Speaker 1: Absolutely! It's a holistic approach that ensures distilled models are efficient and retain high performance levels, mimicking proprietary models.\n",
      "Speaker 2: Umm, what kind of real-world applications do you see for this?\n",
      "Speaker 1: Great question! Knowledge Distillation can revolutionize industries like healthcare, law, finance, and science. For instance, models trained via distillation could assist in accurate medical diagnoses.\n",
      "Speaker 2: Wow, thatâ€™s huge! So it could change the game where precision matters?\n",
      "Speaker 1: Yes, indeed! And not just that; law firms and other fields requiring nuanced understanding can also benefit. Enhanced open-source models can handle complex tasks with sophistication akin to proprietary ones.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Assuming response['message']['content'] contains your string\n",
    "content_string = PODCAST_TEXT\n",
    "\n",
    "# Define a regular expression pattern to match the tuples\n",
    "pattern = r'\\(\"([^\"]+)\", \"([^\"]+)\"\\)'\n",
    "\n",
    "# Find all matches in the string\n",
    "matches = re.findall(pattern, content_string)\n",
    "\n",
    "# Convert matches to a list of tuples\n",
    "podcast_text = [(speaker, text) for speaker, text in matches]\n",
    "\n",
    "# Now you can iterate over the list and access each tuple\n",
    "for speaker, text in podcast_text:\n",
    "    print(f\"{speaker}: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b4c9e-379f-4004-bdd0-93a53f3f7ee0",
   "metadata": {},
   "source": [
    "Most of the times we argue in life that Data Structures isn't very useful. However, this time the knowledge comes in handy. \n",
    "\n",
    "We will take the string from the pickle file and load it in as a Tuple with the help of `ast.literal_eval()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "bd5fd711-6af5-4af3-9c8d-d44bc224f2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speaker 1:\n",
      "  Text segment 1 length: 370 characters\n",
      "  Text segment 2 length: 257 characters\n",
      "  Text segment 3 length: 265 characters\n",
      "  Text segment 4 length: 162 characters\n",
      "  Text segment 5 length: 189 characters\n",
      "  Text segment 6 length: 312 characters\n",
      "  Text segment 7 length: 229 characters\n",
      "  Text segment 8 length: 216 characters\n",
      "  Text segment 9 length: 223 characters\n",
      "  Text segment 10 length: 146 characters\n",
      "  Text segment 11 length: 201 characters\n",
      "  Text segment 12 length: 207 characters\n",
      "  Average length of text segments: 231.42 characters\n",
      "\n",
      "Speaker 2:\n",
      "  Text segment 1 length: 110 characters\n",
      "  Text segment 2 length: 82 characters\n",
      "  Text segment 3 length: 99 characters\n",
      "  Text segment 4 length: 72 characters\n",
      "  Text segment 5 length: 31 characters\n",
      "  Text segment 6 length: 41 characters\n",
      "  Text segment 7 length: 32 characters\n",
      "  Text segment 8 length: 101 characters\n",
      "  Text segment 9 length: 103 characters\n",
      "  Text segment 10 length: 62 characters\n",
      "  Text segment 11 length: 70 characters\n",
      "  Average length of text segments: 73.00 characters\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# Initialize a dictionary to store lengths of text segments per speaker\n",
    "speaker_lengths = defaultdict(list)\n",
    "\n",
    "# Populate the dictionary with lengths of each text segment\n",
    "for speaker, text in podcast_text:\n",
    "    speaker_lengths[speaker].append(len(text))\n",
    "\n",
    "# Calculate and display the length of each text segment and the average length per speaker\n",
    "for speaker, lengths in speaker_lengths.items():\n",
    "    print(f\"\\n{speaker}:\")\n",
    "    for i, length in enumerate(lengths, 1):\n",
    "        print(f\"  Text segment {i} length: {length} characters\")\n",
    "    average_length = sum(lengths) / len(lengths) if lengths else 0\n",
    "    print(f\"  Average length of text segments: {average_length:.2f} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b4c11-5526-4b13-b0a2-8ca541c475aa",
   "metadata": {},
   "source": [
    "#### Generating the Final Podcast\n",
    "\n",
    "Finally, we can loop over the Tuple and use our helper functions to generate the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c640fead-2017-478f-a7b6-1b96105d45d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:   0%|                  | 0/23 [00:00<?, ?segment/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.025945669726715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:   4%|â–         | 1/23 [00:04<01:29,  4.07s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8792193289189597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:   9%|â–Š         | 2/23 [00:05<00:54,  2.62s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0056981722169023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  13%|â–ˆâ–Ž        | 3/23 [00:08<00:52,  2.64s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8066001997508085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  17%|â–ˆâ–‹        | 4/23 [00:09<00:40,  2.15s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0910294639634366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  22%|â–ˆâ–ˆâ–       | 5/23 [00:12<00:40,  2.25s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.858370007309048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  26%|â–ˆâ–ˆâ–Œ       | 6/23 [00:13<00:32,  1.92s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0699168493121225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  30%|â–ˆâ–ˆâ–ˆ       | 7/23 [00:15<00:29,  1.86s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8248742904614821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  35%|â–ˆâ–ˆâ–ˆâ–      | 8/23 [00:16<00:23,  1.56s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851098539826134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 9/23 [00:18<00:23,  1.67s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9569744638818221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  43%|â–ˆâ–ˆâ–ˆâ–‰     | 10/23 [00:18<00:16,  1.28s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.061195356736064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 11/23 [00:21<00:20,  1.72s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8100699475651417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 12/23 [00:21<00:15,  1.41s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9721103796137277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 13/23 [00:24<00:17,  1.80s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730600790167231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 14/23 [00:25<00:12,  1.43s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0508805092553966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 15/23 [00:27<00:13,  1.63s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596796543922568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 16/23 [00:28<00:11,  1.59s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0773340442707755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 17/23 [00:30<00:10,  1.72s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9039281618841253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 18/23 [00:31<00:07,  1.55s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8910212858717518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 19/23 [00:33<00:06,  1.56s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8196867680324589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 20/23 [00:34<00:04,  1.38s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0990108170960058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 21/23 [00:36<00:03,  1.58s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9213531640794541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 22/23 [00:37<00:01,  1.37s/segment]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1042010471522914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating podcast segments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:39<00:00,  1.71s/segment]\n"
     ]
    }
   ],
   "source": [
    "final_audio = None\n",
    "\n",
    "# Calculate the length of each text segment\n",
    "lengths = [len(text) for _, text in podcast_text]\n",
    "\n",
    "# Compute the average length\n",
    "average_length = sum(lengths) / len(lengths) if lengths else 0\n",
    "\n",
    "\n",
    "for speaker, text in tqdm(podcast_text, desc=\"Generating podcast segments\", unit=\"segment\"):\n",
    "    if speaker == \"Speaker 1\":\n",
    "        audio_arr, rate = generate_speaker1_audio(text,average_length)\n",
    "    else:  # Speaker 2\n",
    "        audio_arr, rate = generate_speaker2_audio(text,average_length)\n",
    "    \n",
    "    # Convert to AudioSegment (pydub will handle sample rate conversion automatically)\n",
    "    audio_segment = numpy_to_audio_segment(audio_arr, rate)\n",
    "    \n",
    "    # Add to final audio\n",
    "    if final_audio is None:\n",
    "        final_audio = audio_segment\n",
    "    else:\n",
    "        final_audio += audio_segment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbb2228-8023-44c4-aafe-d6e1d22ff8e4",
   "metadata": {},
   "source": [
    "### Output the Podcast\n",
    "\n",
    "We can now save this as a mp3 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "2eeffdb7-875a-45ec-bdd8-c8c5b34f5a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='./resources2/_podcast2.mp3'>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_audio.export(\"./resources2/_podcast2.mp3\", \n",
    "                  format=\"mp3\", \n",
    "                  bitrate=\"192k\",\n",
    "                  parameters=[\"-q:a\", \"0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce5836",
   "metadata": {},
   "source": [
    "### Suggested Next Steps:\n",
    "\n",
    "- Experiment with the prompts: Please feel free to experiment with the SYSTEM_PROMPT in the notebooks\n",
    "- Extend workflow beyond two speakers\n",
    "- Test other TTS Models\n",
    "- Experiment with Speech Enhancer models as a step 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "26cc56c5-b9c9-47c2-b860-0ea9f05c79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
